<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>CMU 15618 Final Project</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <h1 class="title">A User-level Thread Library Featuring Preemptive Scheduling</h1>
        <p class="author">Yao Xu, Michael Xu</p>
        <p class="date">March 2023</p>

        <div id="figure1">
            <img src="overview.png" alt="img: overview" width="600">
        </div>

        <section class="section">
          <h2>Reports</h2>
          <p>For Milestone and Final report, please see two embeded pdfs at the bottom of this page.</p>
      </section> 

        <section class="section">
            <h2>URL</h2>
            <a href="https://michaelxuuu.github.io/CMU-1561-Final-Project/">https://michaelxuuu.github.io/CMU-1561-Final-Project/</a><br>
            <a href="https://github.com/michaelxuuu/CMU-1561-Final-Project.git">Link to Code</a>
        </section>

        <section class="section">
            <h2>Summary</h2>
            <p>We implemented a user-level thread library that uses hybrid threading model and features preemptive scheduling.</p>
        </section> 
        
        <section class="section">
            <h2>Background</h2>
            <p>Concurrent programming is increasingly necessary due to the rise of multi-core processors, high-performance computing requirements, scalability needs, user expectations for responsiveness, and cost efficiency considerations. Multithreading has become the go-to approach for concurrent programming due to its lower resource consumption and the exploitation of the shared memory model. While POSIX threads are widely used for multithreading implementations, as they are efficient, scalable, reliable, and available on many operating systems, using them to achieve efficient concurrency remains a challenge. </p>
            
            <p>One challenge arises when the number of concurrent tasks increases, potentially causing significant scheduling overhead and overwhelming hardware resources. The thread pool technique has long been used to address this issue, where it abstracts each concurrent task into a unit of work and adds it to a shared work queue. From this queue, threads in the pool grab one unit of work and finish executing it, then proceed to the next until the queue is empty.</p>

            <p>The thread pool can be a neat solution to deal with a huge quantity of tasks while keeping the scheduling overhead bounded. However, it may be insufficient when the running spans of each concurrent task are highly variable. This is especially true if we aim to achieve user-level multitasking, where we can have long-running or persistent tasks. The thread pool may not be a wise solution here, as the tasks that run much longer than the others can cause drastic delay to those far down in the queue, which, in the worst case, may never be executed. That's becasue in the thread pool model subsequent tasks are not executed until all preceding tasks have been completed. If we were still to use pthreads naviely, we would end up spawning hundreds of threads again, one for each task, producing immense overhead and hurting performance.</p>
            
            <p>Clearly, the thread pool model should not be preserved. But how to break the exeuction of long-running blocking tasks without compromising correctness to allow other tasks to run has become the main question. To answer that question, we must introduce the idea of user-level threads, where we turn each unit of work in the work queue (remeber that we are still sticking to the thread pool model) into an execution context, keeping track of the full state of each concurrently running task, and instead of mapping one task to one dedicated POXIS thread, we dynamically decide which POSIX thread in the pool should exeucte which task, so that we can safely break the exeuction of one task, saving its context back to the shared queue, and start the execution of the next user-level thread, loading the corresponding context from the queue. This process is depicted in the <a href="#figure1">figure</a> at the beginning.</p>

            <p>Many programming languages have incorporated support for user-level threads, and we believe it is worth the effort to reinvent the wheel in order to better understand important concepts discussed in lectures, such as lock implementations and lock-free programming. Therefore, we have decided to implement our own user-level thread library.</p>
        </section>

        <section class="section">
            <h2>Platform</h2>
            <p>Any machine with a Linux OS and a multi-core x86-64 processor.</p>
        </section>

        <h2>Milestone Report</h2>
        <iframe src="Milestone_Report.pdf" width="100%" height="500px">
        </iframe>

        <h2>Final Report</h2>
        <iframe src="Final_Report.pdf" width="100%" height="500px">
        </iframe>

       
    </div>
</body>
</html>
