<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>CMU 15618 Final Project</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <h1 class="title">Towards Efficient User-level Preemptive Multitasking</h1>
        <p class="author">Yao Xu, Michael Xu</p>
        <p class="date">March 2023</p>

        <div id="figure1">
            <img src="overview.png" alt="img: overview" width="600">
        </div>

        <section class="section">
          <h2>Reports</h2>
          <p>For Milestone and Final report, please see two pdf files on this web page.</p>
      </section> 

        <section class="section">
            <h2>URL</h2>
            <a href="https://michaelxuuu.github.io/CMU-1561-Final-Project/">https://michaelxuuu.github.io/CMU-1561-Final-Project/</a><br>
            <a href="https://github.com/michaelxuuu/CMU-1561-Final-Project.git">Code</a>
        </section>

        <section class="section">
            <h2>Summary</h2>
            <p>We are going to implement a user-level thread library that uses hybrid threading model and work stealing.</p>
        </section> 
        
        <section class="section">
            <h2>Background</h2>
            <p>Concurrent programming is increasingly necessary due to the rise of multi-core processors, high-performance computing requirements, scalability needs, user expectations for responsiveness, and cost efficiency considerations. Multithreading has become the go-to approach for concurrent programming due to its lower resource consumption and the exploitation of the shared memory model. While POSIX threads are widely used for multithreading implementations, as they are efficient, scalable, reliable, and available on many operating systems, using them to achieve efficient concurrency remains a challenge. </p>
            
            <p>One challenge arises when the number of concurrent tasks increases, potentially causing significant scheduling overhead and overwhelming hardware resources. The thread pool technique has long been used to address this issue, where it abstracts each concurrent task into a unit of work and adds it to a shared work queue. From this queue, threads in the pool grab one unit of work and finish executing it, then proceed to the next until the queue is empty.</p>

            <p>The thread pool can be a neat solution to deal with a huge quantity of tasks while keeping the scheduling overhead bounded. However, it may be insufficient when the running spans of each concurrent task are highly variable. This is especially true if we aim to achieve user-level multitasking, where we can have long-running or persistent tasks. The thread pool may not be a wise solution here, as the tasks that run much longer than the others can cause drastic delay to those far down in the queue, which, in the worst case, may never be executed. That's becasue in the thread pool model subsequent tasks are not executed until all preceding tasks have been completed. If we were still to use pthreads naviely, we would end up spawning hundreds of threads again, one for each task, producing immense overhead and hurting performance.</p>
            
            <p>Clearly, the thread pool model should not be preserved. But how to break the exeuction of long-running blocking tasks without compromising correctness to allow other tasks to run has become the main question. To answer that question, we must introduce the idea of user-level threads, where we turn each unit of work in the work queue (remeber that we are still sticking to the thread pool model) into an execution context, keeping track of the full state of each concurrently running task, and instead of mapping one task to one dedicated POXIS thread, we dynamically decide which POSIX thread in the pool should exeucte which task, so that we can safely break the exeuction of one task, saving its context back to the shared queue, and start the execution of the next user-level thread, loading the corresponding context from the queue. This process is depicted in the <a href="#figure1">figure</a> at the beginning.</p>

            <p>Many programming languages have incorporated support for user-level threads, and we believe it is worth the effort to reinvent the wheel in order to better understand important concepts discussed in lectures, such as lock implementations, work stealing, and lock-free programming. Therefore, we have decided to implement our own user-level thread library.</p>
        </section>
        
        <section class="section">
            <h2>The challenge</h2>
            <p>There are several challenging parts in this project. The first and also the most important one is how to implement user-level threads correctly - what are considered as part of the context of a task, how to assign memory to each task, and how to schedule tasks in a preemptive manner.
            <p>Work stealing can also be tricky to implement efficiently. There are so many design choices that go into this, such as from whom should each worker thread steal, and should the queues be implemented lock-free or not, etc.</p>
            <p>The implementation of locks can also be challenging since there are many ways to implement locks, and deciding which one is best for our circumstance is crucial.</p>
            <p>Another challenging part is to implement resource management such as memory to avoid resource leaking.</p>
        </section>

        <section class="section">
            <h2>Goals & Deliverables</h2>
            <p>We aim to develop a user-level thread library that is fully functional and almost able to be identically used as the Pthread library, with a focus on implementing work stealing. Additionally, we have set several goals that we hope to achieve, such as creating our lock implementation and implementing lock-free work queues. For the demo, our plan is to benchmark both the pthread library and our library and compare their performance results. If we successfully implement our own locks and lock-free work queues, we can further benchmark each implementations to scrutinize the performance variation.</p>
        </section>


        <section class="section">
            <h2>Platform</h2>
            <p>Any machine with a POSIX-compliant OS and a multi-core x86-64 processor.</p>
        </section>

        <section class="section">
          <h2>Schedule</h2>
          <table>
              <tr>
                <th>Date</th>
                <th>Task</th>
              </tr>
              <tr>
                <td>4/1/2023 - 4/6/2023</td>
                <td>Study related work thoroughly and decide API exposed to users</td>
              </tr>
              <tr>
                <td>4/7/2023 - 4/14/2023</td>
                <td>Implement all APIs with distributed work queue</td>
              </tr>
              <tr>
                <td>4/15/2023 - 4/21/2023</td>
                <td>Implement work stealing among workers and write milestone report</td>
              </tr>
              <tr>
                <td>4/22/2023 - 4/28/2023</td>
                <td>Write benchmark programs and conduct performance analysis</td>
              </tr>
              <tr>
                <td>4/29/2023 - 5/3/2023</td>
                <td>Write final report and prepare poster</td>
              </tr>
            </table>
            
      </section>


        <h2>Milestone Report</h2>
        <iframe src="Milestone_Report.pdf" width="100%" height="500px">
        </iframe>

        <h2>Final Report</h2>
        <iframe src="Final_Report.pdf" width="100%" height="500px">
        </iframe>

       
    </div>
</body>
</html>
